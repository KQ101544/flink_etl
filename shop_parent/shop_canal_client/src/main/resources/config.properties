# canal配置
canal.server.ip=node1
canal.server.port=11111
canal.server.destination=example
canal.server.username=root
canal.server.password=123456
canal.subscribe.filter=itcast_shop.*

# zookeeper配置
zookeeper.server.ip=node1:2181,node2:2181,node3:2181

# kafka配置
kafka.bootstrap_servers_config=node1:9092,node2:9092,node3:9092
kafka.batch_size_config=1024
# 1: 表示leader写入成功,就返回.假设leader写完后服务器宕机,还没来得及同步到各个节点
# 0: 异步操作, 不管有没有写入成功都返回,存在数据丢失.
# -1: 当leader写入成功,同时从主节点同步成功以后才返回,可以保证数据不丢失.
# all: leader会等待所有的follower同步完成.这个确保消息不会丢失,除非kafka集群中所有机器挂掉。
kafka.acks=all
kafka.retries=1
kafka.key_serializer_class_config=org.apache.kafka.common.serialization.StringSerializer
# 自定义的value序列化器
kafka.value_serializer_class_config=ProtoBufSerializer
kafka.topic=ods_itcast_shop_mysql